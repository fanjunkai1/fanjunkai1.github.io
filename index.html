<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Junkai Fan</title>

  <meta name="author" content="Junkai Fan">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/cmu-seal-r.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Junkai Fan</name>
                  </p>
                  <!-- <p>I am a CS undergraudate at <a href="http://english.pku.edu.cn/">Peking University</a> starting from Sep. 2016. For now I'm applying for graduate school in Computer Science.
              </p> -->
                  <p>I am a Phd student at the <a href="http://www.patternrecognition.asia/">PCALab</a> of <a
                      href="https://www.njust.edu.cn/">Nanjing University of Science and Technology</a>, where I'm fortunate to be advised by Prof. 
                    <a href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=tLbjVM9T1OzsoNduSpyHQg==&yxsh=4iVdgPyuKTE=&zydm=L-3Jh59wXco=">Jian Yang</a> and co-advised by Prof. <a
                      href="https://sites.google.com/view/junlineu/">Jun Li. </a>
                  </p>
                  <!-- <p>
                I am a research intern at IV-OCR Group, <a href="https://www.sensetime.com/en/">Sensetime AI</a>, starting from Oct. 2019. At Sensetime, I've worked on Form Structuralization and Image Steganography.
              </p> -->
                  <!-- <p>
                I spent last summer as an intern at the <a href="https://www.ri.cmu.edu/">Robotics Institute</a> of <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, where I'm fortunate to be advised by <a href="http://www.cs.cmu.edu/~aayushb/">Aayush Bansal</a> and <a href="https://www.cs.cmu.edu/~deva/">Deva Ramanan</a>.
              </p> -->
                  <p>Prior to joining NJUST, I obtained my M.S degree in 2019 from <a
                      href="https://www.wzu.edu.cn/">Wenzhou University</a>, advised by Prof. <a
                      href="https://inet.wzu.edu.cn/tea_detail.html?abbr=tzz&t=0">Zhengzhou Tang</a>.</p>
                  <p style="text-align:center">
                    <a href="mailto:junkai.fan@njust.edu.cn"> Email </a> &nbsp/&nbsp
                    <!--                 <a href="data/Kangle_CV.pdf">CV</a> &nbsp/&nbsp -->
                    <a href="https://github.com/fanjunkai1"> GitHub </a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?hl=zh-CN&user=KyHsf00AAAAJ&view_op=list_works&sortby=pubdate"> Google Scholar </a> &nbsp/&nbsp
					<a href="images/wechat.jpg"> WeChat </a> 
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a><img style="width:200px;max-width:100%" alt="profile photo" src="images/fanjunkai.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    <!--                 I'm interested in Multimodal Perception, including Computer Vison and Audio Processing. I'm also interested in applications of Information Theory to Maching Learning.  -->

                    <!--                 So far, my research mainly involves computer-aided creation. My research proposal of <em>'Reconstructing and Synthesizing 3D-Aware Content'</em> won 2022 Microsoft Research PhD Fellowship.  -->
                    My research is focused on computer vision and image processing. Iâ€™m particularly interested in image restoration (e.g., real-world dehazing and depth estimation). Representative papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
		  
		<table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

            <tr onmouseout="nsdnet_stop()" onmouseover="nsdnet_start()"> <!-- bgcolor="#ffffd0" -->
			    <td style="padding:20px;width:25%;vertical-align:middle">
					<img src="images/NVDDE/demo.gif" width="300" height="160">
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle><a href="">NVDDE: Joint Non-aligned Regularization Video Dehazing and Depth Estimation in Real-world Scenes</a>
                  </papertitle>
                  <br>
                  <strong>Junkai Fan</strong>, 
				  <a href="https://github.com/w2kun">Kun Wang</a>, 
				  <a href="https://yanzq95.github.io/">Zhiqiang Yan</a>, 
				  <a href="https://sites.google.com/view/junlineu/">Jun Li*</a>, 
				  <a href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=tLbjVM9T1OzsoNduSpyHQg==&yxsh=4iVdgPyuKTE=&zydm=L-3Jh59wXco=">Jian Yang*</a>
                  <br> <br>
                  <em>In review</em>, 2024
                  <br>

                  <p></p>
                  <p>We propose a novel non-aligned learning framework to address video dehazing and depth estimation simultaneously by using the disentangled atmospheric scattering model.</p>
                </td>
              </tr>

            </tbody>
         </table>
		  
		<table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="nsdnet_stop()" onmouseover="nsdnet_start()"> <!-- bgcolor="#ffffd0" -->
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/DVD/pipeline.png" width="300">
					<img src="images/DVD/demo.gif" width="300">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle><a href="">Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance</a>
                  </papertitle>
                  <br>
                  <strong>Junkai Fan</strong>, 
				  <a href="https://wengjiangwei.github.io/">Jiangwei Weng</a>, 
				  <a href="https://github.com/w2kun">Kun Wang</a>, 
				  <a href="https://yijun-yang.github.io/">Yijun Yang</a>, 
				  <a href="http://www.patternrecognition.asia/qian/">Jianjun Qian</a>, 
				  <a href="https://sites.google.com/view/junlineu/">Jun Li*</a>, 
				  <a href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=tLbjVM9T1OzsoNduSpyHQg==&yxsh=4iVdgPyuKTE=&zydm=L-3Jh59wXco=">Jian Yang*</a>
                  <br> <br>
                  <em>CVPR</em>, 2024
                  <br>
                  <a href="projectpage/DVD/index.html">project page</a>  / 
				  <a href="https://github.com/fanjunkai1/DVD">github</a>  /
				  <a href="https://youtu.be/BHFVx8yv4SY">video</a>
                  <p></p>
                  <p>We present an innovative video dehazing framework for real-world driving scenarios, addressing temporal and spatial misalignment 
				  challenges with non-aligned hazy/clear video pairs and a reference frame matching module.</p>
                </td>
              </tr>

            </tbody>
          </table>
		  
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="nsdnet_stop()" onmouseover="nsdnet_start()"> <!-- bgcolor="#ffffd0" -->
                <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src="images/NSDNet/demo.gif" width="300">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <papertitle><a href="https://arxiv.org/pdf/2303.04940v4.pdf">Non-aligned supervision for Real Image Dehazing</a>
                  </papertitle>
                  <br>
                  <strong>Junkai Fan</strong>, 
				  <a href="https://scholar.google.com/citations?hl=zh-CN&user=0wale0IAAAAJ">Fei Guo</a>, 
				  <a href="http://www.patternrecognition.asia/qian/">Jianjun Qian</a>, 
				  <a href="http://implus.github.io/">Xiang Li</a>, 
				  <a href="https://sites.google.com/view/junlineu/">Jun Li*</a>, 
				  <a href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=tLbjVM9T1OzsoNduSpyHQg==&yxsh=4iVdgPyuKTE=&zydm=L-3Jh59wXco=">Jian Yang*</a>
                  <br> <br>
                  <em>arXiv</em>, 2023
                  <br>
                  <a href="projectpage/NSDNet/index.html">project page</a> / 
				  <a href="https://github.com/fanjunkai1/NSDNet">github</a>
                  <p></p>
                  <p>Given an image or video captured in a real foggy scene, our 
				  model is capable of restoring the corresponding clear scene image or video. Moreover, training our model does not require fully aligned ground truth (GT), which helps us collect real hazy scene data.</p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Honors and Awards</heading>
                  <ul>
                    <li>2018, The First Prize of Scholarship, Rank (4/38), Wenzhou University; </li>
                  </ul>
                  <ul>
                    <li>2018, "Xiaoan Wang Award" for Innovation and Entrepreneurship, Rank (2/38), Wenzhou University;</li>
                  </ul>
                  <ul>
                    <li>2017, The Graduate Scientific Research Foundation of Wenzhou University, Rank (1/12), Wenzhou University;</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    This webpage is fork from <a href="https://github.com/jonbarron/jonbarron_website">Jon
                      Barron</a>. Thanks to him!
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>