
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://fanjunkai1.github.io/projectpage/DVD/img/video-demo.mp4">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://fanjunkai1.github.io/projectpage/DVD/"/>
    <meta property="og:title" content="Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance" />
    <meta property="og:description" content="Real driving-video dehazing poses a significant challenge due to the inherent difficulty in acquiring precisely aligned hazy/clear video pairs for effective model training, especially in dynamic driving scenarios with unpredictable weather conditions. 
	In this paper, we propose a pioneering approach that addresses this challenge through a non-aligned regularization strategy. Our core concept involves identifying clear frames that closely match hazy frames, serving as references to supervise a video dehazing network. Our approach comprises 
	two key components: reference matching and video dehazing. Firstly, we introduce a non-aligned reference frame matching module, leveraging an adaptive sliding window to match high-quality reference frames from clear videos. Video dehazing incorporates flow-guided cosine attention sampler and
	deformable cosine attention fusion modules to enhance spatial multi-frame alignment and fuse their improved information. To validate our approach, we collect a GoPro-Hazy dataset captured effortlessly with GoPro cameras in diverse rural and urban road environments. Extensive experiments 
	demonstrate the superiority of the proposed method over current state-of-the-art methods in the challenging task of real driving-video dehazing. />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance" />
    <meta name="twitter:description" content="Real driving-video dehazing poses a significant challenge due to the inherent difficulty in acquiring precisely aligned hazy/clear video pairs for effective model training, especially in dynamic driving scenarios with unpredictable weather conditions. 
	In this paper, we propose a pioneering approach that addresses this challenge through a non-aligned regularization strategy. Our core concept involves identifying clear frames that closely match hazy frames, serving as references to supervise a video dehazing network. Our approach comprises 
	two key components: reference matching and video dehazing. Firstly, we introduce a non-aligned reference frame matching module, leveraging an adaptive sliding window to match high-quality reference frames from clear videos. Video dehazing incorporates flow-guided cosine attention sampler and
	deformable cosine attention fusion modules to enhance spatial multi-frame alignment and fuse their improved information. To validate our approach, we collect a GoPro-Hazy dataset captured effortlessly with GoPro cameras in diverse rural and urban road environments. Extensive experiments 
	demonstrate the superiority of the proposed method over current state-of-the-art methods in the challenging task of real driving-video dehazing. />
	
    <meta name="twitter:image" content="https://fanjunkai1.github.io/projectpage/DVD/img/video-demo.mp4" />


	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’«</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <br><b> Driving-Video Dehazing with Non-Aligned Regularization <br>for Safety Assistance </b></br> 
                <small>
					CVPR 2024
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://fanjunkai1.github.io/">
                          Junkai Fan<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/wengjiangwei">
                          Jiangwei Weng<sup>1</sup>
                        </a>
                    </li>
					<li>
                        <a href="https://w2kun.github.io/">
                          Kun Wang<sup>1</sup>
                        </a>
                    </li>
					<li>
                        <a href="https://yijun-yang.github.io/">
                          Yijun Yang<sup>2</sup>
                        </a>
                    </li>
                    <li>
                        <a href="http://www.patternrecognition.asia/qian/">
                          Jianjun Qian<sup>1</sup>
                        </a>
                    </li>
                    <li>
                        <a href="https://sites.google.com/view/junlineu/">
                          Jun Li*<sup>1</sup>
                        </a>
                    </li>
					<li>
                        <a href="https://gsmis.njust.edu.cn/open/TutorInfo.aspx?dsbh=t6AONNl4pZ5la8fwtaQrXw==&yxsh=z70ppxVSQAs=&zydm=SwsWR9zpmmw=">
                          Jian Yang*<sup>1</sup>
                        </a>
                    </li></br>
					<li>
						<sup>1</sup>Nanjing University of Science and Technology<br>
						<sup>2</sup>The Hong Kong University of Science and Technology (Guangzhou)
					</li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/pdf/2405.09996">
                            <image src="img/DVD_paper.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="video/video-demo.mp4" type="video/mp4">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="" target="popup" onclick="window.open('','popup','width=600,height=400')">
                            <image src="img/database_icon.png" height="60px">
                                <h4><strong>Dataset</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/fanjunkai1/DVD">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4> 
                            </a>
                        </li> 
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
				<h3>
                    Video Results
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/video-demo.mp4" type="video/mp4" />
                </video>
						</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
				Real driving-video dehazing poses a significant challenge due to the inherent difficulty in acquiring precisely aligned hazy/clear video pairs for effective model training, especially in dynamic driving scenarios with unpredictable weather conditions. 
				In this paper, we propose a pioneering approach that addresses this challenge through a non-aligned regularization strategy. Our core concept involves identifying clear frames that closely match hazy frames, serving as references to supervise a video 
				dehazing network. Our approach comprises two key components: reference matching and video dehazing. Firstly, we introduce a non-aligned reference frame matching module, leveraging an adaptive sliding window to match high-quality reference frames from 
				clear videos. Video dehazing incorporates flow-guided cosine attention sampler and deformable cosine attention fusion modules to enhance spatial multi-frame alignment and fuse their improved information. To validate our approach, we collect a GoPro-Hazy
				dataset captured effortlessly with GoPro cameras in diverse rural and urban road environments. Extensive experiments demonstrate the superiority of the proposed method over current state-of-the-art methods in the challenging task of real driving-video dehazing.
                </p>
            </div>
        </div>
		
		
		<div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    GoProHazy and DrivingHazy Datasets
                </h3>
                <table style="width: 100%; border-collapse: collapse;">
				  <tr>
				    <td style="text-align: center;">
						<img src="img/collection-device.png" height="160" width="350"/>
					</td>
				    <td style="text-align: center;">
						<img src="img/collection-method.png" height="160" width="400"/>
					</td>
				  </tr>
				  <tr>
				    <td style="text-align: center;">Collection Settings.</td>
				    <td style="text-align: center;">Collection Method.</td>
				  </tr>
				</table>
				<p class="text-justify">
				<br>
				To collect pairs of hazy/clear video pairs, follow these steps: 1). As illustrated in Collection Method (a), we capture hazy videos in various scenes under hazy weather conditions.
																				2). In Collection Method (b), to maintain consistent scene brightness, we choose overcast days with good visibility 
																				for capturing clear video pairs. Additionally, to ensure the reference clear video matches the hazy scene, 
																				we align clear video capture with the starting point of the hazy videos.
																				3). Video cropping is employed to ensure that the starting and ending points of the collected hazy/clear 
																				video pairs are consistent.
				</p>
			</div>
		</div>
		
		
		<div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Data Statistical
                </h3>
                <div class="text-center">
                    <img src="img/data-statistical.png" width="750"/>
					<p class="text-justify">
					<br>
					Our GoProHazy and DrivingHazy datasets predominantly feature urban road scenarios, where hazy density is primarily observed within a visibility range of 0-100 meters.
					</p>
                </div>
            </div>
        </div>
		


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method
                </h3>
                <div class="text-center">
                    <img src="img/pipeline.png" width="750"/>
					<p class="text-justify">
					<br>
					(a) The overall framework of our driving-video dehazing comprising two crucial components: frame matching and video dehazing. 
					This involves applying frame dehazing to proactively eliminate haze from individual frames. One significant benefit is is the
					effectiveness and efficiency of our method in training the video dehazing network using authentic driving data without requiring strict
					alignment, ultimately producing high-quality results. (b) The illustration depicts the matching process of non-aligned, clear reference
					frames through the utilization of an adaptive sliding window using feature cosine similarity.
					</p>
                </div>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
				<div class="text-center">
                    <img src="img/QuantitativeResults.png" width="750"/>
                </div>
				<br>
                <div class="text-center">
                    <img src="img/GoProHazy-Results.png" width="750"/>
					<p class="text-center">
					Comparison of video dehazing results on the real-world GoProHazy dataset. Our method can remove distant hazy and our method removes distant haze and produces clear images resembling non-aligned reference frames.
					</p>
                </div>
				
				<div class="text-center">
                    <img src="img/DrivingHazy-Results.png" width="750"/>
					<p class="text-center">
					Testing results on DrivingHazy. Our method can perform dehazing in real driving environments while preserving the brightness.
					</p>
                </div>
				
				<div class="text-center">
                    <img src="img/InternetHazy-Results.png" width="750"/>
					<p class="text-center">
					Testing with the pre-trained model provided by the authors on the InternetHazy dataset, our method still performs well in dehazing. The red box corresponds to the zoomed-in patch for better comparison.
					</p>
                </div>

            </div>
        </div>
		
		
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
				
		
                <h3>Citation</h3>	
				
				<p>If you find our work useful in your research, please consider citing:</p>			
				<a href=""><img style="float: left; padding: 10px; PADDING-RIGHT: 30px;" alt="paper thumbnail" src="img/paper_thumbnail.png" width=160></a>

					
				<textarea id="bibtex" class="form-control" readonly>
				
@inproceedings{fan2024driving,
  title={Driving-Video Dehazing with Non-Aligned Regularization for Safety Assistance},
  author={Fan, Junkai and Weng, Jiangwei and Wang, Kun and Yang, Yijun and Qian, Jianjun and Li, Jun and Yang, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26109--26119},
  year={2024}
}</textarea>

            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                Thanks to Ricardo Martin-Brualla and David Salesin for their comments on the text, and to George Drettakis and Georgios Kopanas for graciously assisting us with our baseline evaluation.
                    <br>
                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
